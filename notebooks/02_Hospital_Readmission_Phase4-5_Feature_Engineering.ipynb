{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Readmission Prediction Project\n",
    "## Phase 4-5: Feature Engineering & Data Preparation\n",
    "\n",
    "**Author:** Vindya Siriwardhana  \n",
    "**Previous Findings:**\n",
    "- Readmission rate (<30 days): 11.16%\n",
    "- Class imbalance: 7.96:1 (needs SMOTE!)\n",
    "- Total patients: 101,766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SETUP & LOAD PREVIOUS WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data from Phase 1-3\n",
    "df = pd.read_csv('/mnt/user-data/uploads/diabetic_data.csv')\n",
    "\n",
    "# Recreate binary target\n",
    "df['readmitted_binary'] = (df['readmitted'] == '<30').astype(int)\n",
    "\n",
    "print(f\"‚úÖ Data loaded: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"üìä Readmission rate: {(df['readmitted_binary'].sum()/len(df)*100):.2f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 4: FEATURE ENGINEERING (Steps 10-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "print(\"\\nüîß Creating new features...\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. AGE GROUPS (convert age ranges to numeric mid-points)\n",
    "age_mapping = {\n",
    "    '[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35,\n",
    "    '[40-50)': 45, '[50-60)': 55, '[60-70)': 65, '[70-80)': 75,\n",
    "    '[80-90)': 85, '[90-100)': 95\n",
    "}\n",
    "df_fe['age_numeric'] = df_fe['age'].map(age_mapping)\n",
    "\n",
    "# Age categories\n",
    "df_fe['age_category'] = pd.cut(df_fe['age_numeric'], \n",
    "                                bins=[0, 40, 60, 80, 100], \n",
    "                                labels=['Young', 'Middle', 'Senior', 'Elderly'])\n",
    "\n",
    "print(\"‚úÖ Age features created:\")\n",
    "print(\"   - age_numeric (5-95)\")\n",
    "print(\"   - age_category (Young/Middle/Senior/Elderly)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 2. POLYPHARMACY FLAG (5+ medications = polypharmacy)\n",
    "df_fe['polypharmacy'] = (df_fe['num_medications'] >= 5).astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Polypharmacy feature created:\")\n",
    "print(f\"   Patients with polypharmacy: {df_fe['polypharmacy'].sum():,} ({df_fe['polypharmacy'].mean()*100:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 3. COMORBIDITY COUNT (number of diagnoses)\n",
    "df_fe['comorbidity_count'] = df_fe['number_diagnoses']\n",
    "\n",
    "# High comorbidity flag (7+ diagnoses)\n",
    "df_fe['high_comorbidity'] = (df_fe['number_diagnoses'] >= 7).astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Comorbidity features created:\")\n",
    "print(f\"   Average diagnoses: {df_fe['number_diagnoses'].mean():.1f}\")\n",
    "print(f\"   High comorbidity patients: {df_fe['high_comorbidity'].sum():,} ({df_fe['high_comorbidity'].mean()*100:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 4. LENGTH OF STAY CATEGORIES\n",
    "df_fe['los_category'] = pd.cut(df_fe['time_in_hospital'],\n",
    "                                bins=[0, 3, 7, 14],\n",
    "                                labels=['Short', 'Medium', 'Long'])\n",
    "\n",
    "print(\"\\n‚úÖ Length of stay categories created:\")\n",
    "print(df_fe['los_category'].value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 5. PREVIOUS HOSPITAL VISITS (any emergency or inpatient visits)\n",
    "df_fe['had_emergency'] = (df_fe['number_emergency'] > 0).astype(int)\n",
    "df_fe['had_inpatient'] = (df_fe['number_inpatient'] > 0).astype(int)\n",
    "df_fe['had_outpatient'] = (df_fe['number_outpatient'] > 0).astype(int)\n",
    "\n",
    "# Total previous visits\n",
    "df_fe['total_previous_visits'] = (df_fe['number_emergency'] + \n",
    "                                   df_fe['number_inpatient'] + \n",
    "                                   df_fe['number_outpatient'])\n",
    "\n",
    "print(\"\\n‚úÖ Previous visit features created:\")\n",
    "print(f\"   Patients with emergency history: {df_fe['had_emergency'].sum():,}\")\n",
    "print(f\"   Patients with inpatient history: {df_fe['had_inpatient'].sum():,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 6. LAB PROCEDURES INTENSITY\n",
    "df_fe['high_lab_procedures'] = (df_fe['num_lab_procedures'] > 50).astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Lab procedures feature created:\")\n",
    "print(f\"   Patients with high lab intensity: {df_fe['high_lab_procedures'].sum():,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Encode Diagnosis Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 11: DIAGNOSIS CODE ENCODING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to categorize ICD-9 diagnosis codes\n",
    "def categorize_diagnosis(diag):\n",
    "    \"\"\"Categorize ICD-9 codes into major disease categories\"\"\"\n",
    "    if pd.isna(diag) or diag == '?':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    diag = str(diag)\n",
    "    \n",
    "    # Extract numeric part\n",
    "    if diag.startswith('V') or diag.startswith('E'):\n",
    "        return 'Other'\n",
    "    \n",
    "    try:\n",
    "        code = float(diag)\n",
    "    except:\n",
    "        return 'Other'\n",
    "    \n",
    "    # ICD-9 code ranges\n",
    "    if 390 <= code <= 459 or code == 785:\n",
    "        return 'Circulatory'  # Heart disease, hypertension\n",
    "    elif 460 <= code <= 519 or code == 786:\n",
    "        return 'Respiratory'  # COPD, pneumonia\n",
    "    elif 520 <= code <= 579 or code == 787:\n",
    "        return 'Digestive'  # GI issues\n",
    "    elif 250 <= code < 251:\n",
    "        return 'Diabetes'  # Diabetes complications\n",
    "    elif 800 <= code <= 999:\n",
    "        return 'Injury'  # Injuries, poisoning\n",
    "    elif 140 <= code <= 239:\n",
    "        return 'Neoplasms'  # Cancer\n",
    "    elif 580 <= code <= 629 or code == 788:\n",
    "        return 'Genitourinary'  # Kidney, urinary\n",
    "    elif 710 <= code <= 739:\n",
    "        return 'Musculoskeletal'  # Arthritis, etc.\n",
    "    elif 780 <= code <= 799:\n",
    "        return 'Symptoms'  # General symptoms\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply to all three diagnosis columns\n",
    "df_fe['diag_1_category'] = df_fe['diag_1'].apply(categorize_diagnosis)\n",
    "df_fe['diag_2_category'] = df_fe['diag_2'].apply(categorize_diagnosis)\n",
    "df_fe['diag_3_category'] = df_fe['diag_3'].apply(categorize_diagnosis)\n",
    "\n",
    "print(\"\\n‚úÖ Diagnosis categories created!\")\n",
    "print(\"\\nüìä Primary Diagnosis Distribution:\")\n",
    "print(df_fe['diag_1_category'].value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create flags for major conditions\n",
    "df_fe['has_circulatory'] = (df_fe['diag_1_category'] == 'Circulatory').astype(int)\n",
    "df_fe['has_respiratory'] = (df_fe['diag_1_category'] == 'Respiratory').astype(int)\n",
    "df_fe['has_diabetes_complication'] = (df_fe['diag_1_category'] == 'Diabetes').astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Major condition flags created:\")\n",
    "print(f\"   Circulatory conditions: {df_fe['has_circulatory'].sum():,}\")\n",
    "print(f\"   Respiratory conditions: {df_fe['has_respiratory'].sum():,}\")\n",
    "print(f\"   Diabetes complications: {df_fe['has_diabetes_complication'].sum():,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Medication Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 12: MEDICATION FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Medication columns (all the diabetes medications)\n",
    "med_columns = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "               'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',\n",
    "               'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
    "               'miglitol', 'troglitazone', 'tolazamide', 'insulin',\n",
    "               'glyburide-metformin', 'glipizide-metformin',\n",
    "               'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "               'metformin-pioglitazone']\n",
    "\n",
    "# Count medications that were changed/prescribed\n",
    "# (not 'No' or 'Steady')\n",
    "def count_active_meds(row):\n",
    "    count = 0\n",
    "    for med in med_columns:\n",
    "        if med in row.index and row[med] not in ['No', 'Steady']:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "df_fe['diabetes_meds_count'] = df_fe.apply(count_active_meds, axis=1)\n",
    "\n",
    "print(\"\\n‚úÖ Diabetes medication count created:\")\n",
    "print(df_fe['diabetes_meds_count'].describe())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Medication change flag (from 'change' column)\n",
    "df_fe['medication_changed'] = (df_fe['change'] == 'Ch').astype(int)\n",
    "\n",
    "# On diabetes medication (from 'diabetesMed' column)\n",
    "df_fe['on_diabetes_med'] = (df_fe['diabetesMed'] == 'Yes').astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Medication change features created:\")\n",
    "print(f\"   Medication changed: {df_fe['medication_changed'].sum():,} ({df_fe['medication_changed'].mean()*100:.1f}%)\")\n",
    "print(f\"   On diabetes meds: {df_fe['on_diabetes_med'].sum():,} ({df_fe['on_diabetes_med'].mean()*100:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary of new features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "new_features = [\n",
    "    'age_numeric', 'age_category', 'polypharmacy', 'comorbidity_count',\n",
    "    'high_comorbidity', 'los_category', 'had_emergency', 'had_inpatient',\n",
    "    'had_outpatient', 'total_previous_visits', 'high_lab_procedures',\n",
    "    'diag_1_category', 'diag_2_category', 'diag_3_category',\n",
    "    'has_circulatory', 'has_respiratory', 'has_diabetes_complication',\n",
    "    'diabetes_meds_count', 'medication_changed', 'on_diabetes_med'\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä Created {len(new_features)} new features:\")\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\\nüìà Total features now: {df_fe.shape[1]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 5: DATA PREPARATION (Steps 13-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Select Features & Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 13: FEATURE SELECTION & PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    # Demographics\n",
    "    'age_numeric',\n",
    "    \n",
    "    # Hospital stay\n",
    "    'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "    'num_medications', 'number_diagnoses',\n",
    "    \n",
    "    # Previous visits\n",
    "    'number_outpatient', 'number_emergency', 'number_inpatient',\n",
    "    'total_previous_visits',\n",
    "    \n",
    "    # Engineered features\n",
    "    'polypharmacy', 'high_comorbidity', 'high_lab_procedures',\n",
    "    'had_emergency', 'had_inpatient', 'had_outpatient',\n",
    "    'has_circulatory', 'has_respiratory', 'has_diabetes_complication',\n",
    "    'diabetes_meds_count', 'medication_changed', 'on_diabetes_med'\n",
    "]\n",
    "\n",
    "# Add categorical features (will encode later)\n",
    "categorical_features = ['gender', 'age_category', 'los_category', 'diag_1_category']\n",
    "\n",
    "print(f\"\\nüìä Selected {len(feature_columns)} numerical features\")\n",
    "print(f\"üìä Selected {len(categorical_features)} categorical features\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Handle missing values in selected features\n",
    "df_model = df_fe[feature_columns + categorical_features + ['readmitted_binary']].copy()\n",
    "\n",
    "# Check for missing values\n",
    "missing = df_model.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Missing values found:\")\n",
    "    print(missing[missing > 0])\n",
    "    \n",
    "    # Fill missing with median for numerical, mode for categorical\n",
    "    for col in feature_columns:\n",
    "        if df_model[col].isnull().sum() > 0:\n",
    "            df_model[col].fillna(df_model[col].median(), inplace=True)\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if df_model[col].isnull().sum() > 0:\n",
    "            df_model[col].fillna(df_model[col].mode()[0], inplace=True)\n",
    "    \n",
    "    print(\"‚úÖ Missing values filled!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values in selected features!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Encode categorical features\n",
    "print(\"\\nüîß Encoding categorical features...\")\n",
    "\n",
    "le_dict = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "    print(f\"   ‚úì {col}: {len(le.classes_)} categories\")\n",
    "\n",
    "# Update feature list with encoded columns\n",
    "final_features = feature_columns + [col + '_encoded' for col in categorical_features]\n",
    "\n",
    "print(f\"\\n‚úÖ Total features for modeling: {len(final_features)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare X and y\n",
    "X = df_model[final_features]\n",
    "y = df_model['readmitted_binary']\n",
    "\n",
    "print(f\"\\nüìä X shape: {X.shape}\")\n",
    "print(f\"üìä y shape: {y.shape}\")\n",
    "print(f\"\\nüéØ Target distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\n‚öñÔ∏è Class imbalance: {(y==0).sum() / (y==1).sum():.2f}:1\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Split: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "print(f\"\\nüéØ Train set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"   Readmission rate: {y_train.mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüéØ Test set class distribution:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"   Readmission rate: {y_test.mean()*100:.2f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 14: HANDLING CLASS IMBALANCE (7.96:1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è BEFORE SMOTE:\")\n",
    "print(f\"   Class 0 (Not readmitted): {(y_train==0).sum():,}\")\n",
    "print(f\"   Class 1 (Readmitted <30): {(y_train==1).sum():,}\")\n",
    "print(f\"   Imbalance ratio: {(y_train==0).sum() / (y_train==1).sum():.2f}:1\")\n",
    "\n",
    "# Apply SMOTE\n",
    "print(\"\\nüîß Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ AFTER SMOTE:\")\n",
    "print(f\"   Class 0 (Not readmitted): {(y_train_balanced==0).sum():,}\")\n",
    "print(f\"   Class 1 (Readmitted <30): {(y_train_balanced==1).sum():,}\")\n",
    "print(f\"   Imbalance ratio: {(y_train_balanced==0).sum() / (y_train_balanced==1).sum():.2f}:1\")\n",
    "print(f\"\\nüìä Training set size increased from {X_train.shape[0]:,} to {X_train_balanced.shape[0]:,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize class balance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before SMOTE\n",
    "pd.Series(y_train).value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
    "axes[0].set_title('Before SMOTE (Imbalanced)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Not Readmitted', 'Readmitted <30'], rotation=0)\n",
    "\n",
    "# After SMOTE\n",
    "pd.Series(y_train_balanced).value_counts().plot(kind='bar', ax=axes[1], color=['green', 'red'])\n",
    "axes[1].set_title('After SMOTE (Balanced)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(['Not Readmitted', 'Readmitted <30'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Class imbalance handled!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 15: FEATURE SCALING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on balanced training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same scaler on test\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=final_features)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=final_features)\n",
    "\n",
    "print(\"\\n‚úÖ Features scaled using StandardScaler!\")\n",
    "print(f\"\\nüìä Training set (scaled & balanced): {X_train_scaled.shape}\")\n",
    "print(f\"üìä Test set (scaled): {X_test_scaled.shape}\")\n",
    "\n",
    "# Show example of scaling\n",
    "print(\"\\nüìà Example - 'age_numeric' scaling:\")\n",
    "print(f\"   Original mean: {X_train['age_numeric'].mean():.2f}\")\n",
    "print(f\"   Scaled mean: {X_train_scaled['age_numeric'].mean():.2f}\")\n",
    "print(f\"   Original std: {X_train['age_numeric'].std():.2f}\")\n",
    "print(f\"   Scaled std: {X_train_scaled['age_numeric'].std():.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ SAVE PREPARED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING PREPARED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save processed data\n",
    "import pickle\n",
    "\n",
    "# Save splits\n",
    "data_dict = {\n",
    "    'X_train': X_train_scaled,\n",
    "    'X_test': X_test_scaled,\n",
    "    'y_train': y_train_balanced,\n",
    "    'y_test': y_test,\n",
    "    'feature_names': final_features,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': le_dict\n",
    "}\n",
    "\n",
    "with open('/home/claude/hospital_readmission_prepared_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "\n",
    "print(\"\\nüíæ Saved:\")\n",
    "print(\"   ‚úì X_train (scaled & balanced)\")\n",
    "print(\"   ‚úì X_test (scaled)\")\n",
    "print(\"   ‚úì y_train (balanced)\")\n",
    "print(\"   ‚úì y_test\")\n",
    "print(\"   ‚úì Feature names\")\n",
    "print(\"   ‚úì Scaler\")\n",
    "print(\"   ‚úì Label encoders\")\n",
    "\n",
    "print(\"\\nüìÅ File: hospital_readmission_prepared_data.pkl\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä PHASE 4-5 SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 4-5 COMPLETED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED STEPS:\")\n",
    "print(\"   Step 10: ‚úì Feature engineering (20 new features)\")\n",
    "print(\"   Step 11: ‚úì Diagnosis codes encoded\")\n",
    "print(\"   Step 12: ‚úì Medication features created\")\n",
    "print(\"   Step 13: ‚úì Train-test split (70-30)\")\n",
    "print(\"   Step 14: ‚úì Class imbalance handled (SMOTE)\")\n",
    "print(\"   Step 15: ‚úì Features scaled (StandardScaler)\")\n",
    "\n",
    "print(\"\\nüìä FINAL DATASET STATISTICS:\")\n",
    "print(f\"   ‚Ä¢ Total features: {len(final_features)}\")\n",
    "print(f\"   ‚Ä¢ Training samples (balanced): {X_train_scaled.shape[0]:,}\")\n",
    "print(f\"   ‚Ä¢ Test samples: {X_test_scaled.shape[0]:,}\")\n",
    "print(f\"   ‚Ä¢ Class balance (train): 1:1 (perfect!)\")\n",
    "print(f\"   ‚Ä¢ Features scaled: ‚úì (mean=0, std=1)\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS (Phase 6):\")\n",
    "print(\"   Step 16: Train Logistic Regression (baseline)\")\n",
    "print(\"   Step 17: Train Random Forest\")\n",
    "print(\"   Step 18: Train XGBoost\")\n",
    "print(\"   Step 19: Hyperparameter tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Ready to proceed to Phase 6: Model Building!\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
