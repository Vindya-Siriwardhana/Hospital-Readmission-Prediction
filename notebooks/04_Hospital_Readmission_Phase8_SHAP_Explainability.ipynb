{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Readmission Prediction Project\n",
    "## Phase 8: Explainability (SHAP Analysis)\n",
    "\n",
    "**Author:** Vindya Siriwardhana  \n",
    "**Final Model:** Logistic Regression (Tuned)  \n",
    "**Model Performance:**\n",
    "- AUC-ROC: 0.6380\n",
    "- Recall: 51.36% (catches half of readmissions)\n",
    "- Precision: 16.66% (intentional trade-off for healthcare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SETUP & LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize SHAP's JavaScript visualizations\n",
    "shap.initjs()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load prepared data\n",
    "with open('/home/claude/hospital_readmission_prepared_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "print(\"‚úÖ Data loaded!\")\n",
    "print(f\"\\nüìä Test set: {X_test.shape}\")\n",
    "print(f\"üìä Features: {len(feature_names)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load final model\n",
    "with open('/home/claude/hospital_readmission_final_model.pkl', 'rb') as f:\n",
    "    model_artifacts = pickle.load(f)\n",
    "\n",
    "final_model = model_artifacts['model']\n",
    "model_name = model_artifacts['model_name']\n",
    "metrics = model_artifacts['metrics']\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"\\nüèÜ Model: {model_name}\")\n",
    "print(f\"üìä AUC-ROC: {metrics['auc']:.4f}\")\n",
    "print(f\"üìä Recall: {metrics['recall']:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 8: EXPLAINABILITY (Steps 23-25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 23: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 23: FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For Logistic Regression, use coefficients as importance\n",
    "if hasattr(final_model, 'coef_'):\n",
    "    # Get absolute coefficients\n",
    "    importance = np.abs(final_model.coef_[0])\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä TOP 15 MOST IMPORTANT FEATURES:\")\n",
    "    print(feature_importance.head(15).to_string(index=False))\n",
    "    \n",
    "elif hasattr(final_model, 'feature_importances_'):\n",
    "    # For tree-based models\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': final_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä TOP 15 MOST IMPORTANT FEATURES:\")\n",
    "    print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model doesn't have feature_importances_ or coef_ attribute\")\n",
    "    feature_importance = None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize feature importance\n",
    "if feature_importance is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance (Absolute Coefficient)', fontsize=12)\n",
    "    plt.title('Top 20 Feature Importances', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Feature importance visualized!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 24: SHAP Values Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 24: SHAP VALUES IMPLEMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîß Creating SHAP explainer...\")\n",
    "print(\"‚è≥ This may take 2-3 minutes...\")\n",
    "\n",
    "# Create SHAP explainer based on model type\n",
    "if 'Logistic' in model_name:\n",
    "    # For linear models, use LinearExplainer\n",
    "    explainer = shap.LinearExplainer(final_model, X_train)\n",
    "    print(\"‚úÖ Using LinearExplainer for Logistic Regression\")\n",
    "    \n",
    "elif 'XGBoost' in model_name or 'Random Forest' in model_name:\n",
    "    # For tree-based models, use TreeExplainer\n",
    "    explainer = shap.TreeExplainer(final_model)\n",
    "    print(f\"‚úÖ Using TreeExplainer for {model_name}\")\n",
    "    \n",
    "else:\n",
    "    # Fallback to KernelExplainer (slower but works for all models)\n",
    "    explainer = shap.KernelExplainer(final_model.predict_proba, shap.sample(X_train, 100))\n",
    "    print(\"‚úÖ Using KernelExplainer (general purpose)\")\n",
    "\n",
    "print(\"\\nüîß Calculating SHAP values for test set...\")\n",
    "print(\"‚è≥ This may take 3-5 minutes...\")\n",
    "\n",
    "# Calculate SHAP values for test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# For binary classification, some explainers return list [class0, class1]\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]  # Use positive class (readmission)\n",
    "\n",
    "print(\"\\n‚úÖ SHAP values calculated!\")\n",
    "print(f\"üìä SHAP values shape: {shap_values.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 25: SHAP Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 25: SHAP VISUALIZATIONS\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SHAP Summary Plot (Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nüìä 1. SHAP Summary Plot (Feature Importance)\")\n",
    "print(\"   Shows which features have the biggest impact on predictions\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False, max_display=20)\n",
    "plt.title('SHAP Feature Importance', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Summary plot created!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SHAP Summary Plot (Detailed with Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nüìä 2. SHAP Summary Plot (Detailed)\")\n",
    "print(\"   Shows how feature values affect predictions\")\n",
    "print(\"   Red = High feature value, Blue = Low feature value\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names, \n",
    "                 plot_type='dot', show=False, max_display=20)\n",
    "plt.title('SHAP Values by Feature (Detailed)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Detailed summary plot created!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SHAP Dependence Plots (Top Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nüìä 3. SHAP Dependence Plots (Top 4 Features)\")\n",
    "print(\"   Shows relationship between feature value and prediction impact\")\n",
    "\n",
    "# Get top 4 features by absolute SHAP value\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_feature_indices = np.argsort(mean_abs_shap)[-4:][::-1]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feat_idx in enumerate(top_feature_indices):\n",
    "    shap.dependence_plot(feat_idx, shap_values, X_test, \n",
    "                        feature_names=feature_names,\n",
    "                        show=False, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Dependence Plot: {feature_names[feat_idx]}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dependence plots created!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Individual Patient Explanations (Force Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nüìä 4. Individual Patient Explanations (Force Plots)\")\n",
    "print(\"   Shows why model predicted high/low risk for specific patients\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find examples: high risk patient (correctly identified readmission)\n",
    "high_risk_correct = np.where((y_test == 1) & (y_pred_proba > 0.7))[0]\n",
    "if len(high_risk_correct) > 0:\n",
    "    high_risk_idx = high_risk_correct[0]\n",
    "else:\n",
    "    # Fallback: highest predicted probability for readmission\n",
    "    high_risk_idx = np.argmax(y_pred_proba)\n",
    "\n",
    "# Find low risk patient (correctly identified non-readmission)\n",
    "low_risk_correct = np.where((y_test == 0) & (y_pred_proba < 0.3))[0]\n",
    "if len(low_risk_correct) > 0:\n",
    "    low_risk_idx = low_risk_correct[0]\n",
    "else:\n",
    "    # Fallback: lowest predicted probability\n",
    "    low_risk_idx = np.argmin(y_pred_proba)\n",
    "\n",
    "print(f\"\\nüî¥ HIGH RISK PATIENT (Index {high_risk_idx}):\")\n",
    "print(f\"   Predicted probability: {y_pred_proba[high_risk_idx]:.2%}\")\n",
    "print(f\"   Actual outcome: {'Readmitted' if y_test.iloc[high_risk_idx] == 1 else 'Not readmitted'}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Force plot for high risk patient\n",
    "shap.force_plot(\n",
    "    explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],\n",
    "    shap_values[high_risk_idx],\n",
    "    X_test.iloc[high_risk_idx],\n",
    "    feature_names=feature_names,\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'High Risk Patient Explanation (Index {high_risk_idx})', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(f\"\\nüü¢ LOW RISK PATIENT (Index {low_risk_idx}):\")\n",
    "print(f\"   Predicted probability: {y_pred_proba[low_risk_idx]:.2%}\")\n",
    "print(f\"   Actual outcome: {'Readmitted' if y_test.iloc[low_risk_idx] == 1 else 'Not readmitted'}\")\n",
    "\n",
    "# Force plot for low risk patient\n",
    "shap.force_plot(\n",
    "    explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],\n",
    "    shap_values[low_risk_idx],\n",
    "    X_test.iloc[low_risk_idx],\n",
    "    feature_names=feature_names,\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'Low Risk Patient Explanation (Index {low_risk_idx})', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Force plots created!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. SHAP Waterfall Plot (Alternative Individual Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nüìä 5. SHAP Waterfall Plots\")\n",
    "print(\"   Alternative way to show individual predictions\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# High risk patient\n",
    "plt.sca(axes[0])\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[high_risk_idx],\n",
    "        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],\n",
    "        data=X_test.iloc[high_risk_idx].values,\n",
    "        feature_names=feature_names\n",
    "    ),\n",
    "    show=False,\n",
    "    max_display=15\n",
    ")\n",
    "axes[0].set_title(f'High Risk Patient (Index {high_risk_idx})', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Low risk patient\n",
    "plt.sca(axes[1])\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[low_risk_idx],\n",
    "        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],\n",
    "        data=X_test.iloc[low_risk_idx].values,\n",
    "        feature_names=feature_names\n",
    "    ),\n",
    "    show=False,\n",
    "    max_display=15\n",
    ")\n",
    "axes[1].set_title(f'Low Risk Patient (Index {low_risk_idx})', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Waterfall plots created!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ SAVE SHAP VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING SHAP VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save SHAP explainer and values\n",
    "shap_artifacts = {\n",
    "    'explainer': explainer,\n",
    "    'shap_values': shap_values,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'feature_names': feature_names,\n",
    "    'high_risk_example': high_risk_idx,\n",
    "    'low_risk_example': low_risk_idx\n",
    "}\n",
    "\n",
    "with open('/home/claude/hospital_readmission_shap.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_artifacts, f)\n",
    "\n",
    "print(\"\\nüíæ Saved:\")\n",
    "print(\"   ‚úì SHAP explainer\")\n",
    "print(\"   ‚úì SHAP values for all test samples\")\n",
    "print(\"   ‚úì Example patient indices\")\n",
    "\n",
    "print(\"\\nüìÅ File: hospital_readmission_shap.pkl\")\n",
    "print(\"\\n‚úÖ SHAP analysis complete and saved!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä PHASE 8 SUMMARY & KEY INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 8 COMPLETED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED STEPS:\")\n",
    "print(\"   Step 23: ‚úì Feature importance analysis\")\n",
    "print(\"   Step 24: ‚úì SHAP values calculated\")\n",
    "print(\"   Step 25: ‚úì SHAP visualizations created\")\n",
    "print(\"             ‚Ä¢ Summary plots\")\n",
    "print(\"             ‚Ä¢ Dependence plots\")\n",
    "print(\"             ‚Ä¢ Force plots (individual patients)\")\n",
    "print(\"             ‚Ä¢ Waterfall plots\")\n",
    "\n",
    "# Get top 5 features\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_5_indices = np.argsort(mean_abs_shap)[-5:][::-1]\n",
    "top_5_features = [feature_names[i] for i in top_5_indices]\n",
    "\n",
    "print(\"\\nüìä TOP 5 MOST IMPORTANT FEATURES (by SHAP):\")\n",
    "for i, feat in enumerate(top_5_features, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ Model predictions are now explainable to doctors\")\n",
    "print(\"   ‚Ä¢ Each patient's risk score can be justified with specific factors\")\n",
    "print(\"   ‚Ä¢ SHAP values show which features push risk up or down\")\n",
    "print(\"   ‚Ä¢ Transparent AI = builds trust with clinicians\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS (Phase 9):\")\n",
    "print(\"   Step 26: Build Streamlit dashboard\")\n",
    "print(\"   Step 27: Add file upload functionality\")\n",
    "print(\"   Step 28: Display predictions\")\n",
    "print(\"   Step 29: Add visualizations\")\n",
    "print(\"   Step 30: Add download functionality\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Ready to proceed to Phase 9: Dashboard Creation!\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
